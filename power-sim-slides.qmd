---
title: "Using simulations for power analyses and sample size planning"
subtitle: "<br>"
author: "Matteo Lisi"
format:
  revealjs:
    logo: img/logo-small-london-cmyk.jpg
    footer: "Researcher Support & Development workshop, 15th December 2025"
    incremental: true  
    auto-stretch: true
    code-fold: false   # don’t fold
    code-line-numbers: false
    theme: [default, matteo_rhul.css]
editor: source
keep-md: true
filters: [bg_style.lua]
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```

## Power Analysis: basic concepts

- **Statistical Power:** Probability that a test correctly rejects a false null hypothesis.
- **Effect Size:** Quantitative measure of the magnitude of an effect; it can be standardised (e.g. Cohen's $d$) or not. 


## 


```{r, echo=FALSE}
#| fig.align: 'center'
#| fig.height: 4
#| fig.width: 9.6

m1 <- 0  # mu H0
sd1 <- 1.5 # sigma H0
m2 <- 3.5 # mu HA
sd2 <- 1.5 # sigma HA
 
z_crit <- qnorm(1-(0.05/2), m1, sd1)
 
# set length of tails
min1 <- m1-sd1*4
max1 <- m1+sd1*4
min2 <- m2-sd2*4
max2 <- m2+sd2*4          
# create x sequence
x <- seq(min(min1,min2), max(max1, max2), .01)
# generate normal dist #1
y1 <- dnorm(x, m1, sd1)
# put in data frame
df1 <- data.frame("x" = x, "y" = y1)
# generate normal dist #2
y2 <- dnorm(x, m2, sd2)
# put in data frame
df2 <- data.frame("x" = x, "y" = y2)
 
# Alpha polygon
y.poly <- pmin(y1,y2)
poly1 <- data.frame(x=x, y=y.poly)
poly1 <- poly1[poly1$x >= z_crit, ] 
poly1<-rbind(poly1, c(z_crit, 0))  # add lower-left corner
 
# Beta polygon
poly2 <- df2
poly2 <- poly2[poly2$x <= z_crit,] 
poly2<-rbind(poly2, c(z_crit, 0))  # add lower-left corner
 
# power polygon; 1-beta
poly3 <- df2
poly3 <- poly3[poly3$x >= z_crit,] 
poly3 <-rbind(poly3, c(z_crit, 0))  # add lower-left corner
 
# combine polygons. 
poly1$id <- 3 # alpha, give it the highest number to make it the top layer
poly2$id <- 2 # beta
poly3$id <- 1 # power; 1 - beta
poly <- rbind(poly1, poly2, poly3)
poly$id <- factor(poly$id,  labels=c("power","beta","alpha"))


# plot with ggplot2
ggplot(poly, aes(x,y, fill=id, group=id)) +
  geom_polygon(show_guide=F, alpha=I(8/10)) +
  geom_line(data=df1, aes(x,y, color="H0", group=NULL, fill=NULL), size=1.5, show_guide=F) + 
  geom_line(data=df2, aes(color="HA", group=NULL, fill=NULL),size=1.5, show_guide=F) +
  geom_vline(xintercept = z_crit, size=1, linetype="dashed", color="black") +
  scale_color_manual("Group", 
                     values= c("HA" = "#981e0b","H0" = "black")) +
  scale_fill_manual("test", values= c("alpha" = "#0d6374","beta" = "#be805e","power"="#7cecee")) +
  annotate("segment", x=0.1, y=0.045, xend=1.3, yend=0.01, arrow = arrow(length = unit(0.3, "cm")), size=1, color="black") +
  annotate("text", label="beta", x=0, y=0.05, parse=T, size=8, color="black") +
  annotate("segment", x=4, y=0.043, xend=3.4, yend=0.01, arrow = arrow(length = unit(0.3, "cm")), size=1, color="black") +
  annotate("text", label="frac(alpha,2)", x=4.2, y=0.05, parse=T, size=8, color="black") +
  annotate("segment", x=6, y=0.2, xend=4.5, yend=0.15, arrow = arrow(length = unit(0.3, "cm")), size=1, color="black") +
  annotate("text", label="1-beta", x=6.1, y=0.21, parse=T, size=8, color="black") +
  annotate("text", label="H[0]", x=m1, y=0.28, parse=T, size=8, color="black") +
  annotate("text", label="H[a]", x=m2, y=0.28, parse=T, size=8, color="black") +
  theme(panel.grid.minor = element_blank(),
             panel.grid.major = element_blank(),
             panel.background = element_blank(),
             panel.border = element_blank(),
             axis.line = element_blank(),
             axis.text.x = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks = element_blank(),
             axis.title.x = element_blank(),
             axis.title.y = element_blank())

```

::: {style="font-size: 70%;"}

| Notation  | Meaning                                                                                          |
|:---------:|:------------------------------------------------------------------------------------------------|
| $\beta$   | Probability of a Type II error (false negative)                                                 |
| $1-\beta$ | Probability of a true positive (correctly rejecting the null hypothesis), or **statistical power** |
| $\alpha$  | Probability of a Type I error (false positive)                                                  |
| $1-\alpha$| Probability of a true negative (correctly not rejecting the null hypothesis)                    |

:::


## How to compute statistical power

- For simple tests (e.g. correlations, t-tests), power can be computed analytically (e.g. using the `pwr` package in R).
- More complex designs are often easier to handle using simulation-based approaches.
- Simulations allow us to define a _ground truth_ against which to evaluate a study design.
- Crucially, simulations can incorporate realistic features of both data collection (e.g. attrition, missing data) and inference (e.g. multilevel models, or requiring multiple effects to be significant simultaneously).

## Simulation approach in 1 figure

 

![](img/power_simulation.png){.nostretch fig-align="center" width="70%"}

##

### Simulation approach in simple linear models (regression, ANOVA)

 

::::::::: columns
::::::: {.column width="75%"}

::: nonincremental

 

- Chapter 6 of [our book](https://www.mheducation.co.uk/statistics-for-psychology-using-r-a-linear-models-perspective-9780335252626-emea-group) (available in the Library)

 

- This prior training seminar: [link](https://mlisi.xyz/RHUL-stats/workshops.html#power-analyses-via-data-simulation) 
:::

:::::::


::::::: {.column width="25%"}

![](img/book_cover.png){.nostretch fig-align="center" width="100%"}

:::::::
:::::::::

