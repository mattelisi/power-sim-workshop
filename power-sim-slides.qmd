---
title: "Using simulations for power analyses and sample size planning"
subtitle: "<br>"
author: "Matteo Lisi"
format:
  revealjs:
    logo: img/logo-small-london-cmyk.jpg
    footer: "Researcher Support & Development workshop, 15th December 2025"
    incremental: true  
    auto-stretch: false
    code-fold: false   # don’t fold
    code-line-numbers: false
    theme: [default, matteo_rhul.css]
editor: source
keep-md: true
filters: [bg_style.lua]
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```

## Power Analysis: basic concepts

- **Statistical Power:** Probability that a test correctly rejects a false null hypothesis.
- **Effect Size:** Quantitative measure of the magnitude of an effect; it can be standardised (e.g. Cohen's $d$) or not. 


## 


```{r, echo=FALSE}
#| fig.align: 'center'
#| fig.height: 4
#| fig.width: 9.6

m1 <- 0  # mu H0
sd1 <- 1.5 # sigma H0
m2 <- 3.5 # mu HA
sd2 <- 1.5 # sigma HA
 
z_crit <- qnorm(1-(0.05/2), m1, sd1)
 
# set length of tails
min1 <- m1-sd1*4
max1 <- m1+sd1*4
min2 <- m2-sd2*4
max2 <- m2+sd2*4          
# create x sequence
x <- seq(min(min1,min2), max(max1, max2), .01)
# generate normal dist #1
y1 <- dnorm(x, m1, sd1)
# put in data frame
df1 <- data.frame("x" = x, "y" = y1)
# generate normal dist #2
y2 <- dnorm(x, m2, sd2)
# put in data frame
df2 <- data.frame("x" = x, "y" = y2)
 
# Alpha polygon
y.poly <- pmin(y1,y2)
poly1 <- data.frame(x=x, y=y.poly)
poly1 <- poly1[poly1$x >= z_crit, ] 
poly1<-rbind(poly1, c(z_crit, 0))  # add lower-left corner
 
# Beta polygon
poly2 <- df2
poly2 <- poly2[poly2$x <= z_crit,] 
poly2<-rbind(poly2, c(z_crit, 0))  # add lower-left corner
 
# power polygon; 1-beta
poly3 <- df2
poly3 <- poly3[poly3$x >= z_crit,] 
poly3 <-rbind(poly3, c(z_crit, 0))  # add lower-left corner
 
# combine polygons. 
poly1$id <- 3 # alpha, give it the highest number to make it the top layer
poly2$id <- 2 # beta
poly3$id <- 1 # power; 1 - beta
poly <- rbind(poly1, poly2, poly3)
poly$id <- factor(poly$id,  labels=c("power","beta","alpha"))


# plot with ggplot2
ggplot(poly, aes(x,y, fill=id, group=id)) +
  geom_polygon(show.legend=F, alpha=I(8/10)) +
  geom_line(data=df1, aes(x,y, color="H0", group=NULL, fill=NULL), linewidth=1.5, show.legend=F) + 
  geom_line(data=df2, aes(color="HA", group=NULL, fill=NULL),linewidth=1.5, show.legend=F) +
  geom_vline(xintercept = z_crit, linewidth=1, linetype="dashed", color="black") +
  scale_color_manual("Group", 
                     values= c("HA" = "#981e0b","H0" = "black")) +
  scale_fill_manual("test", values= c("alpha" = "#0d6374","beta" = "#be805e","power"="#7cecee")) +
  annotate("segment", x=0.1, y=0.045, xend=1.3, yend=0.01, arrow = arrow(length = unit(0.3, "cm")), size=1, color="black") +
  annotate("text", label="beta", x=0, y=0.05, parse=T, size=8, color="black") +
  annotate("segment", x=4, y=0.043, xend=3.4, yend=0.01, arrow = arrow(length = unit(0.3, "cm")), size=1, color="black") +
  annotate("text", label="frac(alpha,2)", x=4.2, y=0.05, parse=T, size=8, color="black") +
  annotate("segment", x=6, y=0.2, xend=4.5, yend=0.15, arrow = arrow(length = unit(0.3, "cm")), size=1, color="black") +
  annotate("text", label="1-beta", x=6.1, y=0.21, parse=T, size=8, color="black") +
  annotate("text", label="H[0]", x=m1, y=0.28, parse=T, size=8, color="black") +
  annotate("text", label="H[a]", x=m2, y=0.28, parse=T, size=8, color="black") +
  theme(panel.grid.minor = element_blank(),
             panel.grid.major = element_blank(),
             panel.background = element_blank(),
             panel.border = element_blank(),
             axis.line = element_blank(),
             axis.text.x = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks = element_blank(),
             axis.title.x = element_blank(),
             axis.title.y = element_blank())

```

::: {style="font-size: 70%;"}

| Notation  | Meaning                                                                                          |
|:---------:|:------------------------------------------------------------------------------------------------|
| $\beta$   | Probability of a Type II error (false negative)                                                 |
| $1-\beta$ | Probability of a true positive (correctly rejecting the null hypothesis), or **statistical power** |
| $\alpha$  | Probability of a Type I error (false positive)                                                  |
| $1-\alpha$| Probability of a true negative (correctly not rejecting the null hypothesis)                    |

:::


## How to compute statistical power

- For simple tests (e.g. correlations, t-tests), power can be computed analytically (e.g. using the `pwr` package in R).
- More complex designs are often easier to handle using simulation-based approaches.
- Simulations allow us to define a _ground truth_ against which to evaluate a study design.
- Crucially, simulations can incorporate realistic features of both data collection (e.g. attrition, missing data) and inference (e.g. multilevel models, or requiring multiple effects to be significant simultaneously).

## Simulation approach in 1 figure

 

![](img/power_simulation.png){.nostretch fig-align="center" width="70%"}

##

### Simulation approach in simple linear models (regression, ANOVA)


::::::::: columns
::::::: {.column width="80%"}

::: nonincremental


- Chapter 6 of [our book](https://www.mheducation.co.uk/statistics-for-psychology-using-r-a-linear-models-perspective-9780335252626-emea-group) (available in the Library)


- This prior training seminar: [link](https://mlisi.xyz/RHUL-stats/workshops.html#power-analyses-via-data-simulation) 

:::

:::: fragment

<iframe
  src="https://mlisi.xyz/files/workshops/power_analyses/power_analyses.html#75"
  style="width:80%; height:50vh; border:none;">
</iframe>

::::

:::::::

::::::: {.column width="20%"}

![](img/book_cover.png){.nostretch fig-align="center" width="100%"}

:::::::
:::::::::



## Basics of data simulation {class="inverse"}

- R has some useful functions for generating data randomly drawn from different distributions.

- Random generation functions usually have the `r` prefix, for example:
  - `rnorm()` for the normal distribution
  - `rbinom()` for the binomial distribution

- To see all distributions available in the `stats` package (included in R installation by default) type `?Distributions`

##

:::: columns
::: {.column width="50%"}

Uniform distribution from 0 to 1

```{r}
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 5

N <- 1000
unifSamples <- runif(N, min = 0, max = 1)
hist(unifSamples)
```

:::

::: {.column width="50%"}

Normal distribution with mean 5 and standard deviation 1

```{r}
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 5

normSamples <- rnorm(N, mean = 5, sd = 1)
hist(normSamples)
```

:::
::::

##

:::: columns
::: {.column width="50%"}

Binomial distribution, 10 trials with success probability 0.25

```{r}
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 5

binomSamples <- rbinom(N, size = 10, prob = 0.25)
hist(binomSamples)
```

:::

::: {.column width="50%"}

Student’s t distribution with 4 degrees of freedom

```{r}
#| echo: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 5

tSamples <- rt(N, df = 4)
hist(tSamples)
```

:::
::::

## Ordinal variables

Ordinal variables can be simulated with the `rmultinom()`, but we need to ensure that the probabilities (the parameters of the multinomial distribution) are allocated in a way that is consistent with the analysis model. See example at [mlisi.xyz/RHUL-stats/ordinal.html](https://mlisi.xyz/RHUL-stats/ordinal.html) for simulating a multilevel ordinal logistic model.

::: fragment

<iframe
  src="https://mlisi.xyz/RHUL-stats/ordinal.html"
  style="width:100%; height:80vh; border:none;"
  scrolling="yes">
</iframe>


:::

## Simulating Multivariate Normal Data


```{r}
#| fig-height: 2.5
#| fig-align: center
#| fig-width: 8.5
#| message: false
#| echo: false
#| warning: false

n_obs <- 250
rn5 <- MASS::mvrnorm(n_obs, c(0,0), Sigma = matrix(c(1,-0.7,-0.7,1), nrow = 2))
r00 <- MASS::mvrnorm(n_obs, c(0,0), Sigma = matrix(c(1, 0, 0,1), nrow = 2))
r03 <- MASS::mvrnorm(n_obs, c(0,0), Sigma = matrix(c(1, 0.5,0.5,1), nrow = 2))
r07 <- MASS::mvrnorm(n_obs, c(0,0), Sigma = matrix(c(1, 0.85,0.85,1), nrow = 2))

dat <- data.frame(rbind(rn5, r00, r03, r07))
dat$correlation <- c(rep("rho==-0.7", n_obs),
rep("rho==0",    n_obs),
rep("rho==0.5",  n_obs),
rep("rho==0.85", n_obs))

ggplot(dat, aes(x = X1, y = X2)) +
geom_point(alpha = 0.8) +
facet_grid(. ~ correlation, labeller = label_parsed) +
labs(x = expression(x[1]), y = expression(x[2]))

```

- To simulate multiple variables, we must specify not only their marginal properties (e.g. means and SD) but also how they are correlated.

- Particularly important for longitudinal or repeated-measures designs, where observations from the same participant are typically correlated.

- In multilevel (mixed-effects) models person-specific effects (random effects, interpreted as _latent, individual-level characteristics_) follow a multivariate normal distribution.



##

**Example: 2 correlated normal variables:**

:::: columns
::: {.column width="50%"}

*Define standard deviations and correlations*

::::: nonincremental

- $\sigma_1$ and $\sigma_2$: standard deviations
- $\rho$: correlation

:::::

```{r}
#| echo: true
sigma1 <- 2
sigma2 <- 3
rho <- 0.5
```

:::



::: {.column width="50%"}

:::::: fragment

*Construct the 2×2 variance–covariance matrix*

$$\mathbf{\Sigma} = \left[ \begin{array}{cc} \sigma_1^2 & \sigma_1 \sigma_2 \rho \\ \sigma_1 \sigma_2 \rho & \sigma_2^2 \end{array} \right]$$

```{r}
#| echo: true
sigma <- matrix(
  c(sigma1^2,
    rho * sigma1 * sigma2,
    rho * sigma1 * sigma2,
    sigma2^2),
  ncol = 2, 
  nrow = 2)

print(sigma)
```

::::::

:::

::::


##

:::: columns
::: {.column width="50%"}

Multivariate normal data can then be simulated with `mvrnorm()` (in the `MASS` package)

```{r}
#| echo: true
library(MASS)
data <- mvrnorm(N,
          mu = c(0, 0),
          Sigma = sigma)

head(data)
```
:::


::: {.column width="50%"}

```{r}
#| echo: true
#| fig-height: 2.5
#| fig-width: 2.5
#| fig-align: center

ggplot(as.data.frame(data), 
       aes(x = V1, 
           y = V2)) +
  geom_point(alpha = 0.5) +
  labs(x = "Variable 1", 
       y = "Variable 2")
```


:::

::::

## Worked examples

Link: [mlisi.xyz/power-sim-workshop/](https://mlisi.xyz/power-sim-workshop/)

1. GLMM
2. Experience sampling study


## Further examples

- Simulations for a grant proposal, including of Bayesian multilevel SDT model [OSF link](https://osf.io/bxwdt/overview).

- Registered report: [paper](https://bpspsychub.onlinelibrary.wiley.com/doi/full/10.1111/bjhp.70020), [power simulation script](https://osf.io/89cv5/files/yzdp3)

- PSA-JTF3 collaboration: [stage 1 paper](https://osf.io/preprints/psyarxiv/wegc5_v1), [power analyses](https://osf.io/mquvn/files/dnsz8)


## Simulation without a parametric model

:::: {style="font-size: 75%;"}

Background: 

> _The paper tests whether linguistic measures of surprisal capture attention using a new synchronised tapping task we developed. Participants tap to the beat of a click track while ignoring continuous speech (an audiobook). A decoder is then trained to predict different speech features based on changes in participant’s tapping asynchrony (difference between tap and click time). One outcome measure is the coefficient (in this case Spearman’s rho) representing the correlation between predicted and observed speech features._ 

> _To obtain the null distribution of r-values, we shuffled the tapping data and re-ran the analysis 1000 times. The p-value is the proportion of null r-values that are >= than the median observed r-value._ 

::::

::: {style="font-size: 55%;"}

(Courtesy of Ashley Symons)

:::

 

:::: {style="font-size: 75%;"}

- The editor asked for an experiment, with sample size determined by a power analysis.
- No parametric model assumed for tapping behaviour.
- It is possible to run simulations by _bootstrapping_ (sampling _with replacement_) available data.
- Smaller effect sizes can be simulated by setting a small probability that each bootstrapped tapping sequence is replaced with a shuffled version.

::::



